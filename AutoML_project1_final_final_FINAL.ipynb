{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "xhP-ZsObAZVs",
   "metadata": {
    "id": "xhP-ZsObAZVs"
   },
   "source": [
    "# AutoML project 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grv9zhCBAepS",
   "metadata": {
    "id": "grv9zhCBAepS"
   },
   "source": [
    "Project team: Oliver Püvi, Li Merila, Karolin Rips, Susanna Metsla, Annika Talvet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b250020b",
   "metadata": {
    "id": "b250020b"
   },
   "outputs": [],
   "source": [
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99efd25f",
   "metadata": {
    "id": "99efd25f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, space_eval\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c1a4c",
   "metadata": {
    "id": "297c1a4c"
   },
   "source": [
    "## Reading in the data, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0ad022",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "9b0ad022",
    "outputId": "90be5f78-ada7-4f07-cab3-369ab93fd73a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('insurance.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FWiP9rKxZLol",
   "metadata": {
    "id": "FWiP9rKxZLol"
   },
   "source": [
    "There are 788 missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bMVgx_abYcQx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bMVgx_abYcQx",
    "outputId": "dbb085ee-32f7-4cb1-bb72-9f4cb9828138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df2 = df.dropna()\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J9WUtlZqZW0Q",
   "metadata": {
    "id": "J9WUtlZqZW0Q"
   },
   "source": [
    "Since all the values for those rows are missing, there is no need to impute them; we can simply drop them which is implemented in the code below. We also replace nominal variables (dept and salary) with dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46423cd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46423cd2",
    "outputId": "ce2bafee-8d72-406c-8cfb-18ecc0a32ce6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               float64\n",
      "bmi               float64\n",
      "children          float64\n",
      "charges           float64\n",
      "sex_encoded       float64\n",
      "smoker_encoded    float64\n",
      "region_encoded    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "df = df.dropna()\n",
    "\n",
    "# Initialize label encoders\n",
    "label_encoder_dept = LabelEncoder()\n",
    "label_encoder_salary = LabelEncoder()\n",
    "\n",
    "# Apply Label Encoding to 'dept' and 'salary' columns\n",
    "df['sex_encoded'] = label_encoder_dept.fit_transform(df['sex'])\n",
    "df['smoker_encoded'] = label_encoder_salary.fit_transform(df['smoker'])\n",
    "df['region_encoded'] = label_encoder_salary.fit_transform(df['region'])\n",
    "df['charges'] = (df['charges']-df['charges'].min()) /( df['charges'].max() -df['charges'].min())\n",
    "\n",
    "\n",
    "\n",
    "# Drop original 'dept' and 'salary' columns\n",
    "encoded_df = df.drop(['sex', 'smoker', 'region'], axis=1)\n",
    "\n",
    "# Ensure the DataFrame is of type float64\n",
    "encoded_df = encoded_df.astype('float64')\n",
    "\n",
    "# Check data types\n",
    "print(encoded_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2ROwahuZ-L5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "c2ROwahuZ-L5",
    "outputId": "6ddfc974-eae9-49e1-93a6-f1ca0d5bf681"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_encoded</th>\n",
       "      <th>smoker_encoded</th>\n",
       "      <th>region_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.207025</td>\n",
       "      <td>30.663397</td>\n",
       "      <td>1.094918</td>\n",
       "      <td>0.193916</td>\n",
       "      <td>0.505232</td>\n",
       "      <td>0.204783</td>\n",
       "      <td>1.515695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.049960</td>\n",
       "      <td>6.098187</td>\n",
       "      <td>1.205493</td>\n",
       "      <td>0.193301</td>\n",
       "      <td>0.500160</td>\n",
       "      <td>0.403694</td>\n",
       "      <td>1.104885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.296250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>34.693750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi     children      charges  sex_encoded  \\\n",
       "count  1338.000000  1338.000000  1338.000000  1338.000000  1338.000000   \n",
       "mean     39.207025    30.663397     1.094918     0.193916     0.505232   \n",
       "std      14.049960     6.098187     1.205493     0.193301     0.500160   \n",
       "min      18.000000    15.960000     0.000000     0.000000     0.000000   \n",
       "25%      27.000000    26.296250     0.000000     0.057757     0.000000   \n",
       "50%      39.000000    30.400000     1.000000     0.131849     1.000000   \n",
       "75%      51.000000    34.693750     2.000000     0.247700     1.000000   \n",
       "max      64.000000    53.130000     5.000000     1.000000     1.000000   \n",
       "\n",
       "       smoker_encoded  region_encoded  \n",
       "count     1338.000000     1338.000000  \n",
       "mean         0.204783        1.515695  \n",
       "std          0.403694        1.104885  \n",
       "min          0.000000        0.000000  \n",
       "25%          0.000000        1.000000  \n",
       "50%          0.000000        2.000000  \n",
       "75%          0.000000        2.000000  \n",
       "max          1.000000        3.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f16e25",
   "metadata": {
    "id": "d3f16e25"
   },
   "source": [
    "## Baseline\n",
    "\n",
    "To construct the baseline, we are trying a set of possible machine learning algorithms (13 algorithms) using their default hyperparamters and we choose the one with the highest performance for comparison (baseline model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2045b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: MSE = 0.010967954600655885\n",
      "Ridge Regression: MSE = 0.010960374581455878\n",
      "Lasso: MSE = 0.036034381276254246\n",
      "Elastic Net: MSE = 0.03455210190454312\n",
      "Bayesian Ridge Regression: MSE = 0.010964964161007174\n",
      "Decision Tree: MSE = 0.01198289440772746\n",
      "Random Forest: MSE = 0.008758034538563957\n",
      "Gradient Boosting Regressor: MSE = 0.007859261892098237\n",
      "AdaBoost Regressor: MSE = 0.009153800430342463\n",
      "ExtraTrees Regressor: MSE = 0.00948879524610876\n",
      "KNeighbors Regressor: MSE = 0.038504238389515055\n",
      "Support Vector Regressor: MSE = 0.023616965884986924\n",
      "Gaussian Process Regressor: MSE = 0.04751194054713433\n",
      "\n",
      "Baseline Model: Gradient Boosting Regressor with MSE = 0.007859261892098237\n"
     ]
    }
   ],
   "source": [
    "X = encoded_df.drop('charges', axis = 1)\n",
    "y = encoded_df['charges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)\n",
    "\n",
    "seed=43\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(random_state=seed),\n",
    "    \"Lasso\": Lasso(random_state=seed),\n",
    "    \"Elastic Net\": ElasticNet(random_state=seed),\n",
    "    \"Bayesian Ridge Regression\": BayesianRidge(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=seed),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=seed),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=seed),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=seed),\n",
    "    \"ExtraTrees Regressor\": ExtraTreesRegressor(random_state=seed),\n",
    "    \"KNeighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Gaussian Process Regressor\": GaussianProcessRegressor(random_state=seed)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    results[name] = mse\n",
    "\n",
    "for name, mse in results.items():\n",
    "    print(f\"{name}: MSE = {mse}\")\n",
    "\n",
    "baseline_model_name = min(results, key=results.get)\n",
    "baseline_mse = results[baseline_model_name]\n",
    "\n",
    "print(f\"\\nBaseline Model: {baseline_model_name} with MSE = {baseline_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eImXL6R-d9PV",
   "metadata": {
    "id": "eImXL6R-d9PV"
   },
   "source": [
    "## Studying the potential pipeline structure - gradient boost\n",
    "\n",
    "Based on the problem at hand, we study the potential pipeline structure,\n",
    "algorithms or feature transformers at each step, hyper-parameters ranges. We are using hyperOpt with the potential search space to beat the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f933e2b",
   "metadata": {},
   "source": [
    "class sklearn.ensemble.RandomForestRegressor(n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d2ab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███| 1500/1500 [08:57<00:00,  2.79trial/s, best loss: 0.005296118354639145]\n",
      "Best preprocessor: StandardScaler\n",
      "Best model: GradientBoostingRegressor\n",
      "Best hyperparameters: {'learning_rate': 0.07702998502400535, 'max_depth': 3, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 10, 'n_estimators': 50, 'subsample': 0.6040597570679456}\n",
      "Test MSE: 0.004710674538073604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from hyperopt import hp, fmin, rand, Trials, STATUS_OK, space_eval\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Feature and target separation\n",
    "X = encoded_df.drop('charges', axis=1)  # Features\n",
    "y = encoded_df['charges']               # Target\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining a joint search space for hyperparameter optimization\n",
    "space = {\n",
    "    'regressor': hp.choice('regressor', [\n",
    "        {\n",
    "            'model': GradientBoostingRegressor,\n",
    "            'n_estimators': hp.choice('n_estimators', [50, 100, 200, 300, 400, 500]),\n",
    "            'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "            'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "            'max_depth': hp.choice('max_depth', [3, 5, 7, 9, None]),\n",
    "            'min_samples_split': hp.choice('min_samples_split', [2, 4, 6, 8, 10]),\n",
    "            'min_samples_leaf': hp.choice('min_samples_leaf', [1, 2, 4, 6, 8]),\n",
    "            'max_features': hp.choice('max_features', ['sqrt', 'log2', None])\n",
    "        }\n",
    "    ]),\n",
    "\n",
    "    'preprocessor': hp.choice('preprocessor', [\n",
    "        {'standardscaler': StandardScaler},\n",
    "        {'minmaxscaler': MinMaxScaler}\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Defining a function to optimize\n",
    "def objective(params):\n",
    "    regressor_params = params['regressor']\n",
    "    preprocessor_params = params['preprocessor']\n",
    "\n",
    "    preprocessor = list(preprocessor_params.values())[0]()\n",
    "    regressor_model = regressor_params['model']\n",
    "    regressor_args = {k: v for k, v in regressor_params.items() if k != 'model'}\n",
    "    regressor = regressor_model(**regressor_args)\n",
    "\n",
    "    pipeline = make_pipeline(preprocessor, regressor)\n",
    "    score = -cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "# Optimizing hyperparameters\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=1500, trials=trials)\n",
    "\n",
    "# Extracting the best parameters\n",
    "parameter_values = space_eval(space, best_params)\n",
    "best_preprocessor = list(parameter_values['preprocessor'].values())[0]\n",
    "best_regressor = parameter_values['regressor']['model']\n",
    "remove_model = parameter_values['regressor'].pop('model')\n",
    "best_param_values = parameter_values['regressor']\n",
    "\n",
    "# Train the best model on the entire training data\n",
    "best_pipeline = make_pipeline(best_preprocessor(), best_regressor(**best_param_values))\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred_test = best_pipeline.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Results\n",
    "print(f\"Best preprocessor: {best_preprocessor.__name__}\")\n",
    "print(f\"Best model: {best_regressor.__name__}\")\n",
    "print(f\"Best hyperparameters: {best_param_values}\")\n",
    "print(f\"Test MSE: {test_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbae338d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 50/50 [01:03<00:00,  1.28s/trial, best loss: 0.06677529123256261]\n",
      "Best preprocessor: StandardScaler\n",
      "Best RandomForest model: RandomForestRegressor\n",
      "Optimized hyperparameters: {'bootstrap': True, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 500}\n",
      "Test MSE: 0.007707672927334427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from hyperopt import hp, fmin, rand, Trials, STATUS_OK, space_eval\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "features = encoded_df.drop('charges', axis=1)\n",
    "target = encoded_df['charges']\n",
    "\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(features, target, test_size=0.2, random_state=43)\n",
    "\n",
    "hyperparam_space_rf = {\n",
    "    'rf_regressor': {\n",
    "        'model': RandomForestRegressor,\n",
    "        'n_estimators': hp.choice('rf_n_estimators', [50, 100, 200, 300, 400, 500]),\n",
    "        'max_depth': hp.choice('rf_max_depth', [5, 10, 15, 20, None]),\n",
    "        'min_samples_split': hp.choice('rf_min_samples_split', [2, 4, 6, 8, 10]),\n",
    "        'min_samples_leaf': hp.choice('rf_min_samples_leaf', [1, 2, 4, 6, 8]),\n",
    "        'max_features': hp.choice('rf_max_features', ['sqrt', 'log2', None]),\n",
    "        'bootstrap': hp.choice('rf_bootstrap', [True, False])\n",
    "    },\n",
    "    'preprocessor': hp.choice('preprocessor_rf', [\n",
    "        {'standardscaler': StandardScaler},\n",
    "        {'minmaxscaler': MinMaxScaler}\n",
    "    ])\n",
    "}\n",
    "\n",
    "def objective_rf(params):\n",
    "    regressor_params_rf = params['rf_regressor'].copy()  # Make a copy of the parameters\n",
    "    preprocessor_params_rf = params['preprocessor']\n",
    "\n",
    "    # Remove the 'model' key from the regressor parameters\n",
    "    regressor_params_rf.pop('model', None)\n",
    "\n",
    "    preprocessor_rf = list(preprocessor_params_rf.values())[0]()\n",
    "    rf_model = RandomForestRegressor(**regressor_params_rf)\n",
    "\n",
    "    pipeline_rf = make_pipeline(preprocessor_rf, rf_model)\n",
    "    score_rf = -cross_val_score(pipeline_rf, X_train_rf, y_train_rf, cv=5, scoring='neg_root_mean_squared_error').mean()\n",
    "\n",
    "    return {'loss': score_rf, 'status': STATUS_OK}\n",
    "\n",
    "trials_rf = Trials()\n",
    "best_params_rf = fmin(fn=objective_rf, space=hyperparam_space_rf, algo=rand.suggest, max_evals=50, trials=trials_rf)\n",
    "\n",
    "optimized_params_rf = space_eval(hyperparam_space_rf, best_params_rf)\n",
    "best_preprocessor_rf = list(optimized_params_rf['preprocessor'].values())[0]\n",
    "rf_regressor_params = optimized_params_rf['rf_regressor']\n",
    "rf_regressor_params.pop('model', None)\n",
    "best_rf_regressor = RandomForestRegressor(**rf_regressor_params)\n",
    "optimized_pipeline_rf = make_pipeline(best_preprocessor_rf(), best_rf_regressor)\n",
    "optimized_pipeline_rf.fit(X_train_rf, y_train_rf)\n",
    "y_pred_rf = optimized_pipeline_rf.predict(X_test_rf)\n",
    "test_mse_rf = mean_squared_error(y_test_rf, y_pred_rf)\n",
    "\n",
    "print(f\"Best preprocessor: {best_preprocessor_rf.__name__}\")\n",
    "print(f\"Best RandomForest model: {best_rf_regressor.__class__.__name__}\")\n",
    "print(f\"Optimized hyperparameters: {rf_regressor_params}\")\n",
    "print(f\"Test MSE: {test_mse_rf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5458bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best preprocessor: StandardScaler\n",
      "Best RandomForest model: RandomForestRegressor\n",
      "Optimized hyperparameters: {'bootstrap': True, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 500}\n",
      "Test MSE: 0.007689209812016932\n"
     ]
    }
   ],
   "source": [
    "optimized_params_rf = space_eval(hyperparam_space_rf, best_params_rf)\n",
    "best_preprocessor_rf = list(optimized_params_rf['preprocessor'].values())[0]\n",
    "\n",
    "# Remove the 'model' key from the regressor parameters\n",
    "rf_regressor_params = optimized_params_rf['rf_regressor']\n",
    "rf_regressor_params.pop('model', None)\n",
    "\n",
    "best_rf_regressor = RandomForestRegressor(**rf_regressor_params)\n",
    "optimized_pipeline_rf = make_pipeline(best_preprocessor_rf(), best_rf_regressor)\n",
    "optimized_pipeline_rf.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "y_pred_rf = optimized_pipeline_rf.predict(X_test_rf)\n",
    "test_mse_rf = mean_squared_error(y_test_rf, y_pred_rf)\n",
    "\n",
    "print(f\"Best preprocessor: {best_preprocessor_rf.__name__}\")\n",
    "print(f\"Best RandomForest model: {best_rf_regressor.__class__.__name__}\")\n",
    "print(f\"Optimized hyperparameters: {rf_regressor_params}\")\n",
    "print(f\"Test MSE: {test_mse_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fJ-Faa46eVVK",
   "metadata": {
    "id": "fJ-Faa46eVVK"
   },
   "source": [
    "## Monitoring the performance of the constructed pipeline\n",
    "\n",
    "Monitoring the the performance of the constructed pipeline from the previous step across different time budgets (number of iterations) and reporting the least time budget that you are able to outperform the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ezyumyOjey0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezyumyOjey0b",
    "outputId": "c64f0c29-dc98-4e59-c24a-61c0f9feca04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008455846103965475 0.007859261892098237\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for trial in trials:\n",
    "  trial_nr = trial['tid']+1\n",
    "  pipeline_mse_trial = trial['result']['loss']\n",
    "  if (pipeline_mse_trial < baseline_mse):\n",
    "    #print(f\"Trial {trial_nr}: Pipeline MSE is SMALLER than baseline MSE.\")\n",
    "    \n",
    "    break\n",
    "  else:\n",
    "    #print(f\"Trial {trial_nr}: Pipeline MSE is bigger than baseline MSE.\")\n",
    "    print(pipeline_mse_trial, baseline_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sCf5rTEheu0T",
   "metadata": {
    "id": "sCf5rTEheu0T"
   },
   "source": [
    "## Statistical test\n",
    "\n",
    "Determining whether the difference in performance between the constructed pipeline and the baseline is statistically significant."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
